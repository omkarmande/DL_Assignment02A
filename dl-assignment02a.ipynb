{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"pip install wandb","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!wandb login","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torchvision import datasets, transforms\nfrom torch.utils.data import DataLoader, Subset, ConcatDataset\nfrom sklearn.model_selection import train_test_split\nimport wandb\nfrom tqdm import tqdm\nimport os\nimport random\nimport numpy as np\nimport matplotlib.pyplot as plt","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Trying to set device as GPU if available\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\ntorch.manual_seed(42)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Sweep Configurations that will be used with Bayesian Optimization\nsweep_config = {\n    'method': 'bayes',\n    'metric': {'name': 'val_accuracy', 'goal': 'maximize'},\n    'parameters': {\n        'filters': {\n            'values': [\n                [32, 32, 32, 32, 32],\n                [32, 64, 128, 256, 512],\n                [32, 64, 128, 64, 32],\n                [64, 128, 256, 128, 64],\n                [64, 128, 256, 128, 8],\n            ]\n        },\n        'activation': {'values': ['ReLU', 'GELU', 'SiLU', 'Mish']},\n        'dropout': {'values': [0.2, 0.3]},\n        'batch_norm': {'values': [True, False]},\n        'data_aug': {'values': [True, False]},\n        'batch_size': {'values': [32, 64]},\n        'lr': {'values': [1e-3, 1e-4]},\n        'epochs': {'value': 10}\n    }\n}","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Data Loading and Transforming\ndef load_data(data_aug, batch_size):\n    base_transform = [\n        transforms.Resize((224, 224)),\n        transforms.ToTensor(),\n        transforms.Normalize((0.5,), (0.5,))\n    ]\n    if data_aug:\n        transform = transforms.Compose([\n            transforms.RandomHorizontalFlip(),\n            transforms.RandomRotation(15),\n            *base_transform\n        ])\n    else:\n        transform = transforms.Compose(base_transform)\n\n    dataset = datasets.ImageFolder(\"/kaggle/input/inaturalist/inaturalist_12K/train\", transform=transform)\n    targets = [sample[1] for sample in dataset.samples]\n    #Spliting train data into train and validation\n    train_idx, val_idx = train_test_split(range(len(dataset)), stratify=targets, test_size=0.2, random_state=42)\n\n    train_loader = DataLoader(Subset(dataset, train_idx), batch_size=batch_size, shuffle=True, num_workers=2)\n    val_loader = DataLoader(Subset(dataset, val_idx), batch_size=batch_size, shuffle=False, num_workers=2)\n    return train_loader, val_loader","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# CNN Model Definition\nclass CNN(nn.Module):\n    def __init__(self, filters, activation_fn, batch_norm, dropout):\n        super(CNN, self).__init__()\n        layers = []\n        in_channels = 3 #RGB channel\n        for out_channels in filters:\n            layers.append(nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1))\n            if batch_norm:\n                layers.append(nn.BatchNorm2d(out_channels))\n            layers.append(activation_fn())\n            layers.append(nn.MaxPool2d(2))\n            in_channels = out_channels\n        #convolution layer adding\n        self.conv = nn.Sequential(*layers)\n        #Fully connected layer initialization (dense)\n        self.fc = nn.Sequential(\n            nn.Flatten(),\n            nn.Linear(filters[-1] * (224 // (2 ** 5)) ** 2, 256),\n            nn.Dropout(dropout),\n            nn.ReLU(),\n            nn.Linear(256, 10)\n        )\n    #forward pass \n    def forward(self, x):\n        return self.fc(self.conv(x))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Training & Evaluation with W&B Logging\ndef train_eval(config=None):\n    with wandb.init(config=config) as run:\n        config = wandb.config\n        #assigning unique name to identify different runs\n        run.name = f\"ac-{config.activation}_filters-{'-'.join(map(str, config.filters))}_drop-{config.dropout}\"\n\n        model = CNN(config.filters, activation_map[config.activation], config.batch_norm, config.dropout).to(device)\n        train_loader, val_loader = load_data(config.data_aug, config.batch_size)\n        optimizer = optim.Adam(model.parameters(), lr=config.lr)\n        criterion = nn.CrossEntropyLoss()\n\n        for epoch in range(config.epochs):\n            model.train()\n            total_loss, correct, total = 0, 0, 0\n            for images, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}\"):\n                images, labels = images.to(device), labels.to(device)\n                optimizer.zero_grad()\n                outputs = model(images)\n                #calculating loss\n                loss = criterion(outputs, labels)\n                loss.backward()\n                optimizer.step()\n                total_loss += loss.item()\n                preds = outputs.argmax(1)\n                correct += (preds == labels).sum().item()\n                total += labels.size(0)\n            #accuracies of train and validation\n            train_acc = correct / total\n            model.eval()\n            val_loss, val_correct, val_total = 0, 0, 0\n            with torch.no_grad():\n                for images, labels in val_loader:\n                    images, labels = images.to(device), labels.to(device)\n                    outputs = model(images)\n                    val_loss += criterion(outputs, labels).item()\n                    preds = outputs.argmax(1)\n                    val_correct += (preds == labels).sum().item()\n                    val_total += labels.size(0)\n\n            val_acc = val_correct / val_total\n\n            #logging the calculated loss and accuracies to wandb\n            wandb.log({\n                \"epoch\": epoch + 1,\n                \"train_loss\": total_loss / len(train_loader),\n                \"train_accuracy\": train_acc * 100,\n                \"val_loss\": val_loss / len(val_loader),\n                \"val_accuracy\": val_acc * 100\n            })","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"activation_map = {\n    \"ReLU\": nn.ReLU,\n    \"GELU\": nn.GELU,\n    \"SiLU\": nn.SiLU,\n    \"Mish\": nn.Mish\n}","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Running 100 sweeps on wandb\nsweep_id = wandb.sweep(sweep_config, project=\"Assignment_02A\")\nwandb.agent(sweep_id, function=train_eval, count=100)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Best Configuration according to training and validation data \nbest_config = {\n    \"filters\": [64, 128, 256, 128, 64],\n    \"activation\": \"SiLU\",\n    \"dropout\": 0.3,\n    \"batch_norm\": True,\n    \"data_aug\": False,\n    \"batch_size\": 32,\n    \"lr\": 1e-4,\n    \"epochs\": 10\n}","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Loading Train and Test data\ndef load_final_data(batch_size, data_aug):\n    base_transform = [\n        transforms.Resize((224, 224)),\n        transforms.ToTensor(),\n        transforms.Normalize((0.5,), (0.5,))\n    ]\n    if data_aug:\n        transform = transforms.Compose([\n            transforms.RandomHorizontalFlip(),\n            transforms.RandomRotation(15),\n            *base_transform\n        ])\n    else:\n        transform = transforms.Compose(base_transform)\n\n    dataset = datasets.ImageFolder(\"/kaggle/input/inaturalist/inaturalist_12K/train\", transform=transform)\n    train_idx, val_idx = train_test_split(range(len(dataset)), stratify=[s[1] for s in dataset.samples], test_size=0.2, random_state=42)\n    merged_dataset = ConcatDataset([Subset(dataset, train_idx), Subset(dataset, val_idx)])\n    train_loader = DataLoader(merged_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n\n    test_dataset = datasets.ImageFolder(\"/kaggle/input/inaturalist/inaturalist_12K/val\", transform=transforms.Compose(base_transform))\n    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n    return train_loader, test_loader, test_dataset.classes\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Training using Best Configurations\ndef train_final_model():\n    train_loader, test_loader, class_names = load_final_data(best_config['batch_size'], best_config['data_aug'])\n    model = CNN(best_config['filters'], activation_map[best_config['activation']], \n                best_config['batch_norm'], best_config['dropout']).to(device)\n    optimizer = optim.Adam(model.parameters(), lr=best_config['lr'])\n    criterion = nn.CrossEntropyLoss()\n\n    for epoch in range(best_config['epochs']):\n        model.train()\n        total_loss, correct, total = 0, 0, 0\n        for images, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}\"):\n            images, labels = images.to(device), labels.to(device)\n            optimizer.zero_grad()\n            outputs = model(images)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n            total_loss += loss.item()\n            preds = outputs.argmax(1)\n            correct += (preds == labels).sum().item()\n            total += labels.size(0)\n\n        print(f\"Epoch {epoch+1}: Train Acc = {correct / total:.4f} | Loss = {total_loss / len(train_loader):.4f}\")\n    \n    return model, test_loader, class_names\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Final Test Accuracy\ndef compute_test_accuracy(model, test_loader):\n    model.eval()\n    correct, total = 0, 0\n    with torch.no_grad():\n        for images, labels in test_loader:\n            images, labels = images.to(device), labels.to(device)\n            outputs = model(images)\n            preds = outputs.argmax(1)\n            correct += (preds == labels).sum().item()\n            total += labels.size(0)\n    acc = correct / total * 100\n    print(f\"\\nFinal Test Accuracy: {acc:.2f}%\")\n    wandb.log({\"Test Accuracy (%)\": acc})\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Prediction Grid Visualization(True and Predicted)\ndef show_test_predictions(model, test_loader, class_names):\n    model.eval()\n    all_images, all_labels, all_preds = [], [], []\n\n    with torch.no_grad():\n        for images, labels in test_loader:\n            images, labels = images.to(device), labels.to(device)\n            outputs = model(images)\n            preds = outputs.argmax(1)\n            all_images.extend(images.cpu())\n            all_labels.extend(labels.cpu())\n            all_preds.extend(preds.cpu())\n\n    idxs = random.sample(range(len(all_images)), 30)\n    fig, axes = plt.subplots(10, 3, figsize=(12, 40), dpi=150)\n    for i, idx in enumerate(idxs):\n        row, col = i // 3, i % 3\n        img = all_images[idx].permute(1, 2, 0) * 0.5 + 0.5\n        axes[row, col].imshow(img)\n        axes[row, col].axis(\"off\")\n        true_label = class_names[all_labels[idx]]\n        pred_label = class_names[all_preds[idx]]\n        axes[row, col].set_title(f\"T: {true_label}\\nP: {pred_label}\",\n                                 fontsize=12,\n                                 color='green' if true_label == pred_label else 'red')\n\n    plt.tight_layout()\n    plt.savefig(\"test_predictions_grid.png\", bbox_inches='tight')\n    wandb.log({\"Prediction Grid\": wandb.Image(\"test_predictions_grid.png\")})\n    plt.show()\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Run sweep for test data on wandb and log accuracies\nwandb.init(project=\"Assignment_02A\", name=\"test-image\")\nfinal_model, test_loader, class_names = train_final_model()\ncompute_test_accuracy(final_model, test_loader)\nshow_test_predictions(final_model, test_loader, class_names)\nwandb.finish()","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}